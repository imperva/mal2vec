{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../logo.png\" align='center' width=80%>\n",
    "# Overview\n",
    "As data scientists working in a cyber-security company, we wanted to show that Natural Language Processing (NLP) algorithms can be applied to security related events. For this task we used 2 algorithm developed by Google: **Word2vec** ([link](https://arxiv.org/abs/1301.3781)) and **Doc2vec** ([link](https://arxiv.org/abs/1405.4053)). These algorithms use the context of words to extract a vectorized representation (aka embedding) for each word/document in a given vocabulary.  \n",
    "If you want to learn about how **Word2vec** works, you can [start here](https://skymind.ai/wiki/word2vec).\n",
    "\n",
    "Using these algorithms, we managed to model the behavior of common vulnerability scanners (and other client applications) based on their unique 'syntax' of malicious web requests. We named our implementation **Mal2vec**.\n",
    "\n",
    "### About this notebook\n",
    "This notebook contains easy to use widgets to execute each step on your own data. We also include 3 datasets as examples of how to use this project.\n",
    "\n",
    "### Table of contents\n",
    "- [Load csv data file](#Load-CSV-data-file)\n",
    "- [Map columns](#Map-columns)\n",
    "- [Select additional grouping columns](#Select-additional-grouping-columns)\n",
    "- [Create sentences](#Create-sentences)\n",
    "- [Prepare dataset](#Prepare-dataset)\n",
    "- [Train classification model](#Train-classifictaion-model)\n",
    "- [Evaluate the model](#Evaluate-the-model)\n",
    "\n",
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "from IPython.display import display, Markdown, clear_output, HTML\n",
    "def hide_toggle():\n",
    "    # @author: harshil\n",
    "    # @Source: https://stackoverflow.com/a/28073228/6306692\n",
    "    this_cell = \"\"\"$('div.cell.code_cell.rendered.selected')\"\"\"\n",
    "    next_cell = this_cell + '.next()'\n",
    "\n",
    "    toggle_text = 'Show/hide code'  # text shown on toggle link\n",
    "    target_cell = this_cell  # target cell to control with toggle\n",
    "    js_hide_current = ''  # bit of JS to permanently hide code in current cell (only when toggling next cell)\n",
    "\n",
    "    js_f_name = 'code_toggle_{}'.format(str(random.randint(1,2**64)))\n",
    "\n",
    "    html = \"\"\"\n",
    "        <script>\n",
    "            function {f_name}() {{\n",
    "                {cell_selector}.find('div.input').toggle();\n",
    "            }}\n",
    "\n",
    "            {js_hide_current}\n",
    "        </script>\n",
    "\n",
    "        <a href=\"javascript:{f_name}()\">{toggle_text}</a>\n",
    "    \"\"\".format(\n",
    "        f_name=js_f_name,\n",
    "        cell_selector=target_cell,\n",
    "        js_hide_current=js_hide_current, \n",
    "        toggle_text=toggle_text\n",
    "    )\n",
    "\n",
    "    return HTML(html)\n",
    "display(hide_toggle())\n",
    "display(HTML('''<style>.text_cell {background: #E0E5EE;}\n",
    ".widget-inline-hbox .widget-label{width:120px;}</style>'''))\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import ipywidgets as widgets\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from classify import prepare_dataset, train_classifier\n",
    "from vizualize import draw_model, plot_model_results\n",
    "from sentensize import create_sentences, dump_sentences "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load CSV data file\n",
    "### Ready to use dataset - Customer Complaints\n",
    "- Open source dataset by U.S. gov ([link](https://catalog.data.gov/dataset/consumer-complaint-database))\n",
    "- **Events**: the first word in the column 'issue' \n",
    "- **Label**: the product\n",
    "- **Groupping by**: 'Zip code'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "display(hide_toggle())\n",
    "\n",
    "df = None\n",
    "def load_csv(btn):\n",
    "    global df\n",
    "    clear_output()\n",
    "    display(hide_toggle())\n",
    "    display(widgets.VBox([filename_input, nrows_input]))\n",
    "    display(HTML('<img src=\"../loading.gif\" alt=\"Drawing\" style=\"width: 50px;\"/>'))\n",
    "\n",
    "    nrows = int(nrows_input.value)\n",
    "    df = pd.read_csv(filename_input.value, nrows=nrows if nrows > 0 else None)\n",
    "\n",
    "    clear_output()\n",
    "    display(hide_toggle())\n",
    "    display(widgets.VBox([filename_input, nrows_input, load_button]))\n",
    "    print('Loaded {} rows'.format(df.shape[0]))\n",
    "    display(df.sample(n=5))\n",
    "\n",
    "filename_input = widgets.Text(description='CSV file:', value='data/complaints.gz')\n",
    "nrows_input = widgets.Text(description='Rows limit:', value='0')\n",
    "\n",
    "load_button = widgets.Button(description='Load CSV')\n",
    "load_button.on_click(load_csv)\n",
    "\n",
    "widgets.VBox([filename_input, nrows_input, load_button])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Map columns\n",
    "The data should have at least 3 columns:\n",
    "- **Timestamp** (int) - if you don't have timestamps, it can also be a simple increasing index\n",
    "- **Event** (string) - rule name, event description, etc. Must be a single word containing only alpha-numeric characters\n",
    "- **Label** (string) - type of event. This will be later used to create the classification model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "time_column_input, event_column_input, label_column_input = None, None, None\n",
    "def show_dropdown(obj):\n",
    "    global time_column_input, event_column_input, label_column_input\n",
    "    time_column_input = widgets.Dropdown(options=df.columns, description='Time column:')\n",
    "    event_column_input = widgets.Dropdown(options=df.columns, value='Issue', description='Event column:')\n",
    "    label_column_input = widgets.Dropdown(options=df.columns, value='Product', description='Label column:')\n",
    "\n",
    "    clear_output()\n",
    "    display(hide_toggle())\n",
    "    display(widgets.VBox([show_dropdown_button, time_column_input, event_column_input, label_column_input]))\n",
    "    \n",
    "show_dropdown_button = widgets.Button(description='Refresh')\n",
    "show_dropdown_button.on_click(show_dropdown)\n",
    "show_dropdown(None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select additional grouping columns\n",
    "Select those columns which represents unique sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkboxes = None\n",
    "def show_checkboxes(obj):\n",
    "    global checkboxes\n",
    "    checkboxes = {k:widgets.Checkbox(description=k) for k in df.columns if k not in [time_column_input.value, \n",
    "                                                                                 event_column_input.value, \n",
    "                                                                                 label_column_input.value\n",
    "                                                                                ]}\n",
    "    checkboxes['ZIP code'].value = True\n",
    "    clear_output()\n",
    "    display(hide_toggle())\n",
    "    display(widgets.VBox([show_checkboxes_button] + [checkboxes[x] for x in checkboxes]))\n",
    "\n",
    "show_checkboxes_button = widgets.Button(description='Refresh')\n",
    "show_checkboxes_button.on_click(show_checkboxes)\n",
    "show_checkboxes(None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create sentences\n",
    "This cell will group events into sentences (using the grouping columns selected).  \n",
    "It will then split sentences if to consecutive events are separated by more than the given timeout (default: 300 seconds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "display(hide_toggle())\n",
    "\n",
    "dataset_name = os.path.splitext(os.path.basename(filename_input.value))[0]\n",
    "sentences_df, sentences_filepath = None, None\n",
    "def sentences(obj):\n",
    "    global sentences_df, sentences_filepath\n",
    "    clear_output()\n",
    "    display(hide_toggle())\n",
    "    display(HTML('<img src=\"../loading.gif\" alt=\"Drawing\" style=\"width: 50px;\"/>'))\n",
    "\n",
    "    groupping_columns = [x for x in checkboxes if checkboxes[x].value]\n",
    "    sentences_df = create_sentences(df, \n",
    "                                    time_column_input.value, \n",
    "                                    event_column_input.value, \n",
    "                                    label_column_input.value, \n",
    "                                    groupping_columns,\n",
    "                                    timeout=300\n",
    "                                   )\n",
    "    sentences_filepath = dump_sentences(sentences_df, dataset_name)\n",
    "\n",
    "    clear_output()\n",
    "    display(hide_toggle())\n",
    "    display(sentence_button)\n",
    "    print('Created {} sentences. Showing 5 examples:'.format(sentences_df.shape[0]))\n",
    "    display(sentences_df.sample(n=5))\n",
    "\n",
    "sentence_button = widgets.Button(description='Start')\n",
    "\n",
    "display(sentence_button)\n",
    "sentence_button.on_click(sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare dataset\n",
    "1) Train a doc2vec model to extract the embedding vector from each sentence.  \n",
    "**Parameters**:  \n",
    "*vector_size*: the size of embedding vector. Increasing this parameters might improve accuracy, but will take longer to train (int, default=30)  \n",
    "*epochs*: how many epochs should be applied during training. Increasing this parameters might improve accuracy, but will take longer to train  (int, default=50)  \n",
    "*min_sentence_count*: don't classify labels with small amount of sentences (int, default=200)  \n",
    "\n",
    "2) Prepare dataset\n",
    "- Infer the embedding vector for each sample in the data set\n",
    "- Perform [stratified sampling](https://en.wikipedia.org/wiki/Stratified_sampling) for each label\n",
    "- Split to train/test sets 80%-20%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "display(hide_toggle())\n",
    "\n",
    "X_train, X_test, y_train, y_test, classes = None, None, None, None, None\n",
    "def dataset(obj):\n",
    "    global sentences_df, sentences_filepath, dataset_name, X_train, X_test, y_train, y_test, classes\n",
    "    clear_output()\n",
    "    display(hide_toggle())\n",
    "    display(HTML('<img src=\"../loading.gif\" alt=\"Drawing\" style=\"width: 50px;\"/>'))\n",
    "\n",
    "    X_train, X_test, y_train, y_test, classes = prepare_dataset(sentences_df, \n",
    "                                                                sentences_filepath, \n",
    "                                                                dataset_name,\n",
    "                                                                vector_size=30,\n",
    "                                                                epochs=50,\n",
    "                                                                min_sentence_count=200\n",
    "                                                               )\n",
    "\n",
    "    dataset_button.description = 'Run Again'\n",
    "    clear_output()\n",
    "    display(hide_toggle())\n",
    "    print('Dataset ready!')\n",
    "    display(dataset_button)\n",
    "\n",
    "dataset_button = widgets.Button(description='Start')\n",
    "\n",
    "display(dataset_button)\n",
    "dataset_button.on_click(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train classification model\n",
    "Train a deep neural network to classify each sentence to its correct label for 500 epochs (automatically stop when training no longer improves results)\n",
    "\n",
    "For the purpose of this demo, the network architecture and hyper-parameters are constant. Feel free the modify to code and improve the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "display(hide_toggle())\n",
    "\n",
    "history, report, df_cm = None, None, None\n",
    "def train(obj):\n",
    "    global dataset_name, X_train, X_test, y_train, y_test, classes, history, report, df_cm\n",
    "    train_button.description = 'Train Again'\n",
    "\n",
    "    clear_output()\n",
    "    display(hide_toggle())\n",
    "    display(train_button)\n",
    "\n",
    "    history, report, df_cm = train_classifier(X_train, X_test, y_train, y_test, classes, dataset_name)\n",
    "    \n",
    "\n",
    "train_button = widgets.Button(description='Start')\n",
    "\n",
    "display(train_button)\n",
    "train_button.on_click(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate the model\n",
    "Plot the results of the model:\n",
    "- **Loss** - how did the model progress during training (lower values mean better performance)\n",
    "- **Accuracy** - how did the model perform on the validation set (higher values are better)\n",
    "- **Confusion Matrix** - mapping each of the model's predictions (x-axis) to its true label (y-axis). Correct predictions are placed on the main diagonal (brighter is better)\n",
    "- **Detailed report** - for each label, show the following metrics: precision, recall, f1-score ([read more here](https://towardsdatascience.com/accuracy-precision-recall-or-f1-331fb37c5cb9)). The 'support' metric is the number of instances in that class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "display(hide_toggle())\n",
    "\n",
    "def evaluate(btn):\n",
    "    global history, report, df_cm\n",
    "    \n",
    "    clear_output()\n",
    "    evaluate_button.description = 'Refresh'\n",
    "    display(hide_toggle())\n",
    "    display(evaluate_button)\n",
    "    plot_model_results(history, report, df_cm, classes)\n",
    "    \n",
    "evaluate_button = widgets.Button(description='Evaluate Model')\n",
    "display(evaluate_button)\n",
    "evaluate_button.on_click(evaluate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (Anaconda3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
